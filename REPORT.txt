LINEAR REGRESSION: we tried to add a bias term to increase our results 
|
|-> SCORE WITH BIAS: loss = 0.45761875084887216 
|-> SCORE WITHOUT BIAS: loss = 0.4576186 
|-> CONCLUSION: We see that the appending of the bias term increase a bit the loss function (WHY??? -> ask to a TA)

LOGISTIC REGRESSION: to find our optimal parameters without cross-validation, we just went by hand until we find something convincing
|
|-> SCORE WITHOUT CROSS-VALIDATION [lr=0.0001, max_iters=50]: accuracy = 77.28426395939087 ; macro F1 score = 0.63641554702023  
|-> SCORE WITH CROSS VALIDATION: accuracy = ??? ; macro F1 score = ???  
|-> CONCLUSION: [compare result with and without using cross-validation]

RIDGE REGRESSION: we tried to add a bias term to increase our results 
|
|-> SCORE WITH BIAS: loss = ??? 
|-> SCORE WITHOUT BIAS: loss = ??? 
|-> CONCLUSION: We see that the appending of the bias term (???)

CROSS VALIDATION: ??? 



